---
title: "Demystifying Machine Learning - Training Exercises"
author: Alexander Lemm
output: 
  tutor::tutorial:
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(tutor)
library(magrittr)
library(httr)


tutor_options(exercise.completion = TRUE)
knitr::opts_chunk$set(echo = FALSE)
source("global.r")


```

## Overview

This course will give you a hands-on introduction to the typical steps of the data science process. Leveraging real-life credit data we will show you how to import, clean and explore data. Moreover, we will teach you how to model credit risk by using decision trees and random forests in R.  


## R Introduction

### FP vs OOP

Before we get started, you need to know a little bit about R and its underlying principles. R is a *functional programming language* in contrast to Java which is object-oriented and which most of you use on a daily basis. Usually, when you work with R, you use a functional programming style.

Functional languages make a lot of sense when you have a more or less fixed set of *things*, and as your code evolves, you primarily add new operations on existing things. For instance, R comes with 20 types of objects that represent the basic building blocks for data analysis. Surprisingly, those 20 objects are all you need for getting things done when analyzing data.

When you develop new stuff with a functional mindset you typically start by thinking about what your function should do. Next, you think about what objects get passed into the function as arguments and finally, you think about what objects are returned by the function.

When looking at code you can spot the difference between the two programming styles as follows: In an object-oriented language you would call a method of an object using the "dot" notation: *object.function(argument)*. In contrast, in a functional programming language the call would look as follows *function(object, argument)*.

In this course we will primarily deal with the following two object types: *data frames* and *atomic vectors*.

A *data frame* is used for storing data tables. Just think of it as being a single Excel sheet. Ideally, each line of the sheet represents one *observation/case*. Each column contains measurements on one variable which are specific for the respective observation. In R speech a data frame is a list of vectors of equal length. Continuing with the Excel analogy the sheet's columns are the vectors.

The *atomic vector* is the simplest R data type. Atomic vectors are linear vectors of a single primitive type. The four common types of atomic vectors are logical, integer, double, and character. Individual numbers or strings, which are scalars in other languages, are actually vectors of length one in R.

But enough theory for now, time to practice. In the following exercises you will learn some basic R commands to explore data frames and vectors in detail. 


### Exercises

#### Exercise 1

Every R session comes with a bunch of data sets which are directly available even though the user didn't load them explicitly into memory. We will take advantage of that fact and take a closer look at the `mtcars` data set. The data set was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and aspects of automobile design and performance for several automobiles (1973â€“74 models).

In the console below type `mtcars` and hit CTRL + Enter or click on the green 'Run Code' button. This will print the content of the data set to the console. 

```{r mtcars-print, exercise=TRUE}


```


#### Exercise 2

Check out the class of the mtcars object by typing `class(mtcars)`

```{r mtcars-class, exercise=TRUE}


```

```{r mtcars-class-quiz}

question("What is the class of the mtcars object?",
    answer("numeric vector"),
    answer("list"),
    answer("data frame", correct = TRUE),
    answer("matrix"),
    allow_retry = TRUE
  )


```


#### Exercise 3

Usually, you would not print the entire content of a data frame to the console like you did it in exercise 1. Instead, you would use the `head()` and `tail()` function to get a first glimpse on the data. By default, they return the first and respectively last 6 rows of a data frame. Try out both functions with the `mtcars` data frame below. 

```{r mtcars-head, exercise=TRUE}


```


#### Exercise 4

To get some information about the data frame's dimensions you can use `nrow()`, `ncol()`, and `dim()`. Before trying out all three functions in the console below, think a few seconds about them. What do you expect them to return?

```{r mtcars-dim, exercise=TRUE}


```

```{r mtcars-dim-quiz}

question("Of how many rows and columns does the mtcars data frame consist?",
    answer("11 columns and 32 rows"),
    answer("12 rows and 31 columns"),
    answer("32 rows and 11 columns", correct = TRUE)
  )


```


#### Exercise 5

One or perhaps THE most important function in R is `str()` which shows you the structure of an object. Try it out with the `mtcars` data frame.

```{r mtcars-str, exercise=TRUE}


```

`str()` returns a brief description of the data: 

* The object's class
* The object's dimensionality
* a list of names of the columns including their type and their primary values 


#### Exercise 6

You can access an individual column of a specific data frame object, for instance named `my_data_frame`, using the `$` operator: `my_data_frame$desired_column`. 

In the console below execute `mtcars$mpg`. After that type `mtcars$` and hit 'tab'. This will show you all available columns of the data frame. Select 2-3 different columns and print their content to the console


```{r mtcars-dollar, exercise=TRUE}
mtcars$mpg

```
 

#### Exercise 7

If you like to assign a data frame column's content to a new variable you have to type the following: `new_vector <- my_data_frame$column_name`. Yes, your eyes didn't trick you. Instead of `=`, R uses `<-` as its assignment operator.

In the console below we give you a small example. Go ahead and execute the code. Afterwards, assign the the cylinder column to a new variable `my_cyl` and print it to the console. Compare this output with `mtcars$cyl`.

```{r mtcars-assignment, exercise=TRUE}
my_mpg <- mtcars$mpg

```



```{r mtcars-assignment-quiz}

question("What are the last 3 values of my_cyl when printing it to the console?",
    answer("6, 8, 4", correct = TRUE),
    answer("8, 8, 4"),
    answer("6, 6, 4")
  )

```


## Problem Introduction

### Some theory about credit risk modeling

Modeling credit risk for both personal and company loans/credits is of major importance for banks. Credit risk modeling is all about the event of loan default: the situation a client fails to reimburse all or parts of the loan/credit.

When a bank lends loan to a borrower, it usually transfers the entire amount of the loan to the borrower. Afterwards, the borrower will reimburse this loan amount in smaller chunks including some interest payments over time. There is a certain risk that a borrower will not fully reimburse his loan which results in a loss for the bank.

The components of expected loss (EL) for a bank consists of 3 parts:

* *Probability of default (PD)*: The probability a borrower will fail to fully reimburse his loan
* *Exposure at default (EAD)*:  Amount of loan which still needs to be repaid at time of default
* *Loss given default (LGD)*:  Amount of the loss at default expressed as percentage of the EAD

The expected loss is calculated by multiplying all three measurements: EL = PD x EAD x LGD.

In this course, however, we will only concentrate on the *probability of default (PD)*.

### Introducing the data

Banks keep information on the default behavior of past clients which can be used to predict defaults for new clients. This client information consists of two different types of information:

* Application information
    * Income
    * Marital status
    * ...
* Behavioral information (tracks past behavior of the client)
    * Payment arrears in account history 
    * Spending history
    * ...


The data of past clients which we will use in the remainder of the course to create Machine Learning models to predict the probability of default for new clients looks as follows:


```{r}

head(readRDS("./www/loan_data_raw.rds"), 10)

```


The data set contains information on past loans. Each line represents one customer and his information along with the loan status indicator (`loan_status`) which equals 1 if the customer defaulted and 0 if the customer did not default. The other variables are as follows:

* `loan_amnt`: Amount of the loan
* `int_rate`: Interest rate
* `grade`: Bureau score reflecting credit risk history; A (highest credit worthiness) - G (lowest credit worthiness)
* `empl_length`: Employment length
* `home_ownership`: Home ownership status
* `annual_inc`: Annual income
* `age`: Age


### Exercises

#### Exercise 1

```{r crm-behavioral}

question("Which is the only behavioral variable in the dataset?",
         answer("int_rate"),
         answer("grade", correct = TRUE),
         answer("annual_inc"),
         answer("age")
         )

```




## Importing Data

### Different ways to import data

Right at the beginning you need to import your data into R. Otherwise you would not be able to do data science on it. Typically, that means that you import the data from a database, a file or from a web API into a data frame in R.

The simplest case is obviously importing data from a file. When data is stored in a .csv file you can use the `read.csv()` function to import it. The first argument to `read.csv()` is the name of the file including an absolute or relative path to it.

Right after importing the data you need to check if the import was successful. 


### Excerises


#### Exercise 1


We already loaded the complete raw loan data set for you into memory and stored in the variable `loan_data_raw`. So you don't need to execute `read.csv()` yourself. 

Use the console below to get your answers to the questions of the following quiz leveraging the functions you just learned about in section "R Introduction" (`str`, `head`, etc.). 

```{r check-out-loan-data, exercise=TRUE}

```


```{r check-out-loan-data-quiz}

quiz(caption = "Quiz: Examining loan data",
     question("How many observations are stored in loan_data?",
              answer("8"),
              answer("19829"),
              answer("42"),
              answer("29092", correct = TRUE)
     ),
     question("How many variables are stored in loan_data?",
              answer("19829"),
              answer("42"),
              answer("8", correct = TRUE),
              answer("29091")
     ),
     question("How many variables of type integer are stored in loan_data?",
              answer("3", correct = TRUE),
              answer("4"),
              answer("1")
     ),       
     question("How many variables of type factor are stored in loan_data?",
              answer("3"),
              answer("4", correct = TRUE),
              answer("1")
     ),
     question("What is the annunal income of the last individual in the data set?",
              answer("22000", correct = TRUE),
              answer("200000"),
              answer("18000")
     ),
     question("What is the home ownership status of the second individual in the data set?",
              answer("OWN"),
              answer("RENT", correct = TRUE)
     )
)

```


#### Exercise 2 (Importing data easy is...)

OK, in the following 3 exercises we just gonna have some fun using the Star Wars REST API (http://swapi.co) to download some data directly from the web. This is just a little demo to show you that data scientists may also leverage any kind of web API to gather and analyze data.

```{r prepare-sw-api, warning=FALSE, message=FALSE}

parse_sw_people <- function(x) {
  x %>% httr::content(as = "text") %>% 
    jsonlite::fromJSON() %>% 
    .[["results"]] %>% 
    .[, 1:8] %>% 
    dplyr::mutate(
      height = as.numeric(height),
      mass = as.numeric(mass)
    )
}

people <- GET("http://swapi.co/api/people/") %>% parse_sw_people

sw_bmi <- people$mass / ((people$height/100)^2)

```

The code below will download and parse some Star Wars character related data from the web. Execute it and inspect the `people` variable afterwards.


```{r sw-api-people, exercise=TRUE, exercise.setup = "prepare-sw-api", warning=FALSE, message=FALSE}

people <- GET("http://swapi.co/api/people/") %>% parse_sw_people

```

```{r sw-bmi-people-quiz}

question("Information on how many characters is stored in the people data frame?",
    answer("9"),
    answer("18"),
    answer("10", correct = TRUE)
  )


```



#### Excercise 3

Imagine you are a data scientist interested in the Body Mass Index (BMI) of Star Wars characters. With the data you just downloaded you now can calculate the BMI and directly add it as a new column to the existing `people` data frame. 

In general, the BMI is calculated as follows: bmi = (mass in kg) / ((height in m)^2). 

Fortunately, the math operators in R look exactly the same as in the formula above ("/", "^"). Execute the following code snippet in the console below: `people$mass / ((people$height / 100)^2)` and assign the results to the variable `sw_bmi`. Check out the `sw_bmi` variable afterwards. 


```{r sw-api-bmi, exercise=TRUE, exercise.setup = "prepare-sw-api"}



```

The command above calculated the BMI for each character based on the two columns `mass` and `height`. This command worked because in R most functions are "vectorized".

```{r sw-bmi-vector-quiz}

question("What is the second value in the sw_bmi vector?",
    answer("26.02758"),
    answer("26.89232", correct = TRUE),
    answer("25.08286")
  )


```

#### Exercise 4

We now can add the `sw_bmi` vector as a new column to the data frame `people` using the `$` operator and the `<-` assignment operator.

In the console below type `people$bmi <- sw_bmi` and inspect the entire data frame `people`. Can you explain what the commands you just executed did?


```{r sw-api-new_column, exercise=TRUE, exercise.setup = "prepare-sw-api"}


```


```{r sw-bmi-quiz}

question("What is Darth Vader's BMI?",
    answer("34.00999"),
    answer("26.02758"),
    answer("33.33007", correct = TRUE)
  )


```

## Exploring Data


Typically, the first step in data analysis is exploring the data using **graphical techniques** and **simple descriptive statistics**. Analysts also call this task exploratory data analysis (EDA for short). EDA is not a formal process with a strict set of rules but a very creative process which can vary a lot from dataset to dataset. 

As an analyst you try to achieve to following in the EDA:

* Develop a general understanding and "feeling" of your data
* Identify potential problems such as missing values and outliers
* Identify possible new features (feature engineering)
* Identify possible transformations

Acutally, the easiest way to develop this "feeling" for your data is to use questions to lead your investigation. At the beginning of EDA you should feel free to investigate every idea and every question that comes to your mind. Some of these ideas will turn out all right, and probably a lot will be dead ends. The more questions you ask yourself the more quality questions you end up with. Each additional question that you ask will give you new insights.

There is no guideline or rule set about which questions you should ask to guide your research. However, the following types of questions are always a good starter for making discoveries within your data:

* What type of variation occurs within my variables?
* What is the relationship between my variables and what type of covariation occurs between them?



### View the structure of loan_data
str(loan_data)


### Call table() on loan_status
table(loan_data$loan_status)

### Call prop.table(table()) on loan_status
prop.table(table(loan_data$loan_status))


### Call table() on grade and loan_status


prop.table(table(loan_data_raw$loan_status, loan_data_raw$grade), margin = 2)






## Transforming Data

Goal: Fully pre-process data so that it can go into modeling.
Remark: All of those steps always need to be replicated later for completely new data when we would like to make predictions. 

There a three basic options to deal with missing values in the data:

* Delete rows/columns
* Keep values
* Replace values






## Modeling Data

### Some Machine Learning Theory 


supervised learning 

response variable

explanatory variables

### Decision trees introduction


### Decision tress in R



## Evaluating Data

One simple model vs base line model

